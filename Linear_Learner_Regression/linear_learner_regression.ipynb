{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Defining the s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'data-445'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the file to be read from s3 bucket\n",
    "file_key = 'Chapter3/housing.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Reading the csv file\n",
    "housing = pd.read_csv(file_content_stream)\n",
    "\n",
    "## Defining inputs and target variable\n",
    "X = housing.drop(['MEDV'], axis = 1)\n",
    "Y = housing['MEDV']\n",
    "\n",
    "## Splitting data into training, validation and testing\n",
    "X_train, X_val, Y_train, Y_val =  train_test_split(X, Y, test_size = 0.3, random_state = 618, shuffle = True)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size = 0.5, random_state = 620, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region = boto3.Session().region_name, framework = \"linear-learner\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role,\n",
    "                                       instance_count = 1,\n",
    "                                       instance_type = \"ml.c4.xlarge\",\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sess,\n",
    "                                       )\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 784, \n",
    "                           predictor_type = \"binary_classifier\", \n",
    "                           mini_batch_size = 200)\n",
    "\n",
    "linear.fit({\"train\": s3_train_data})"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
